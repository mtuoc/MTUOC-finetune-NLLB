train_src_file: train.es
train_tgt_file: train.hr
val_src_file: val.es
val_tgt_file: val.hr

src_lang_code: spa_Latn
tgt_lang_code: hrv_Latn

model_name: facebook/nllb-200-distilled-600M
#a local dir or a model to download (Helsinki-NLP/opus-mt-en-es)
max_length: 128
# Define the maximum sentence length

output_dir: "./finetunedmodel"
gpu_log_file: GPU_consumption.log


eval_strategy: epoch
save_strategy: epoch
per_device_train_batch_size: 16
per_device_eval_batch_size: 16
num_train_epochs: 3
weight_decay: 0.01
#save_steps: 500
#save_total_limit: 3
logging_dir: './logs'
logging_steps: 500
load_best_model_at_end: True
# Load the best model when finished training
metric_for_best_model: eval_loss
# Specify the metric to use for early stopping

patience: 3

output_model_name: fine-tuned-NLLB200-distilled-600M
output_tokenizer_name: fine-tuned-NLLB200-distilled-600M
